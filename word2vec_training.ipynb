{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How bias changes with training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook contents:\n",
    "1. Bias metrics in the existing literature\n",
    "2. Training of word2vec on different training datasets (of varying sizes and sources)\n",
    "3. Visualizations and computations of bias metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bias metrics in the existing literature\n",
    "\n",
    "There are 3 prominent metrics in the literature (among others): projection of word embeddings along a gender direction (Bolukbasi, modified by Nissim), WEAT, and WEFAT (Caliskan, Bryson, Narayanan). Below we summarize these papers.\n",
    "\n",
    "#### 1. Bolukbasi et al. (NIPS 2016): \"Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings\" https://arxiv.org/abs/1607.06520\n",
    "\n",
    "#### 2. Nissim, van Noord, and van der Goot (2019): \"Fair is Better than Sensational: Man is to Doctor as Woman is to Doctor\" https://arxiv.org/abs/1905.09866\n",
    "\n",
    "#### 3. Caliskan, Bryson, and Narayanan (Science 2017): \"Semantics derived automatically from language corpora contain human-like biases\" https://purehost.bath.ac.uk/ws/portalfiles/portal/168480066/CaliskanEtAl_authors_full.pdf\n",
    "\n",
    "* IAT is one technique used (outside of word embeddings) to measure implicit human biases:\n",
    "    * \"Implicit Association Test\": assessment (on humans) introduced by Greenwald et al., where a word is categorized into one of two categories, and faster reaction time is considered as more deeply rooted association\n",
    "* Introduces new statistical test **WEAT** (Word Embedding Association Test) to measure biases in word embeddings\n",
    "    * analogous to the IAT: interpretation is \"how separated the two distributions (of associations between target and attribute) are\"\n",
    "    * inputs:\n",
    "        * 2 sets of target words:\n",
    "            * X. programmer/engineer/scientist/...\n",
    "            * Y. nurse/teacher/librarian/...) \n",
    "        * 2 sets of attribute words:\n",
    "            * A. man/male/...\n",
    "            * B. woman/female/...):\n",
    "    * test statistic:\n",
    "        * intuitively, difference between association of two sets of target words, with attributes\n",
    "        * $s(X, Y, A, B) = \\sum_{x \\in X} s(x, A, B) - \\sum_{y \\in Y} s(y, A, B)$\n",
    "        * $s(w, A, B) = mean_{a \\in A} cos(w, a) - mean_{b \\in B} cos(w, b)$\n",
    "    * p-value of permutation test (permuting target words)\n",
    "        * $Pr_i[s(X_i, Y_i, A, B) > s(X, Y, A, B)]$\n",
    "        * effect size: $\\frac{mean_{x \\in X} s(x, A, B) - mean_{y \\in Y} s(y, A, B)}{sd_{w \\in X \\bigcup Y} s(w, A, B)}$\n",
    "    * Obtains similar results to original finding in Greenwald et al.\n",
    "* Introduces **WEFAT** (Word Embedding Factual Association Test):\n",
    "    * instead of using target word embeddings, use real-valued factual property, e.g. % female workers in occupation)\n",
    "    * difference in avg. cos similarity (between attribute A and target property, vs. attribute B and target property), divided by standard deviation of cos similarity (across each combination of attribute - target property) \n",
    "    * high correlation between % of women in different occupations, vs. strength of association of word vector w/ female gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. word2vec model training\n",
    "\n",
    "Dataset grid: 20 datasets\n",
    "\n",
    "Training size:\n",
    "* 25%\n",
    "* 50%\n",
    "* 75%\n",
    "* 100%\n",
    "\n",
    "Source:\n",
    "* TweetEval: labeled tweet dataset (e.g. sentiment, hate, emotion)\n",
    "* Reddit: unlabeled reddit post dataset\n",
    "* CNN/DailyMail: news article text with highlights\n",
    "* Pretrained historical word vectors: pre-trained word vectors trained on historical books from various decades from 1880s - 1990s\n",
    "* The New York Times Annotated Corpus: articles with metadata from 1987-2007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualization of bias metrics\n",
    "\n",
    "Useful package for automatic computation of the above bias metrics: https://docs.responsibly.ai/notebooks/demo-word-embedding-bias.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
